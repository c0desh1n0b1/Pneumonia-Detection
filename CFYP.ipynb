{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob#Return all file paths which match a specific pattern \n",
    "import os#Operating system interface\n",
    "import numpy as np#Numerical library\n",
    "import pandas as pd#Dataframe library\n",
    "import matplotlib.pyplot as plt#Plotting library\n",
    "\n",
    "\n",
    "import seaborn as sns#Plotting library\n",
    "import tensorflow as tf#Machine learning library\n",
    "from tensorflow import keras#Keras a high level API for TensorFlow\n",
    "from tensorflow.keras.applications import vgg16#VGG16 model from Keras\n",
    "from tensorflow.keras.applications import resnet50#ResNet50 model from Keras\n",
    "from tensorflow.keras.applications import inception_v3#InceptionV3 model from Keras\n",
    "from tensorflow.keras.applications import efficientnet#EfficientNet model from Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator# Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/tedjo/Downloads/XRAY/SplitData\"#Path to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Path to dataset\n",
    "train_path = os.path.join(path, 'train')\n",
    "#Test Path to dataset\n",
    "test_path = os.path.join(path, 'test')\n",
    "#Validation Path to dataset\n",
    "val_path = os.path.join(path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COVID 19 Path to images\n",
    "c_train_images = glob.glob(f'{train_path}/COVID/*.jpg')\n",
    "#Normal Path to images\n",
    "n_train_images = glob.glob(f'{train_path}/NORMAL/*.jpg')\n",
    "#Pneumonia Path to images\n",
    "p_train_images = glob.glob(f'{train_path}/PNEUMONIA/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the number of images for each class \n",
    "#Place them in to a dataframe array\n",
    "dataFrame = pd.DataFrame(np.concatenate([[0]*len(c_train_images), [1]*len(n_train_images), [2]*len(p_train_images)]), columns=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the count \n",
    "ax = sns.countplot(dataFrame['Label'],data=dataFrame)\n",
    "#label the number of data in each label\n",
    "abs_counts = dataFrame['Label'].value_counts()\n",
    "rel_values = dataFrame['Label'].value_counts(normalize=True).values\n",
    "#0 represents COVID-19\n",
    "#1 represents Normal\n",
    "#2 represents Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a piechart to presents the percentage of data\n",
    "#0 represents COVID-19\n",
    "#1 represents Normal\n",
    "#2 represents Pneumonia\n",
    "labels = [f'{p[0]} ({p[1]:.2f}%)' for p in zip(abs_counts.index, rel_values*100)]\n",
    "plt.pie(rel_values, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 model\n",
    "model16 = vgg16.VGG16(weights='imagenet', include_top=False,input_shape=(64,64,3))\n",
    "\n",
    "#The layers in this layers are frozen meaning that the layer will not be trained\n",
    "#This is will prevent the weight to be modified\n",
    "for i in model16.layers:\n",
    "    i.trainable = False\n",
    "\n",
    "output = model16.output\n",
    "#The Average Pooling Layer\n",
    "output = keras.layers.GlobalAveragePooling2D()(output)#Pooling operation for spatial data(Data that directly or indirectly references spatial information)\n",
    "output = keras.layers.Dense(128, activation='relu')(output)#Dense indicates the number of neurons in the layer, 128 Neurons \n",
    "#The classification Layer\n",
    "predictions = keras.layers.Dense(12, activation='softmax')(output)#12 Neurons \n",
    "#The final Model\n",
    "model16 = keras.models.Model(inputs=model16.input, outputs=predictions)#Group the layers into an object with training and interface features\n",
    "#Learning rate\n",
    "lr = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr, decay_steps=10000, decay_rate=0.96, staircase=True)#Learning Rate schedule that uses exponential decay schedule\n",
    "#Model Compilation\n",
    "model16.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing a summary of the model\n",
    "model16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "train_dataset = ImageDataGenerator(rescale=1./255,shear_range=10, zoom_range = 0.2, horizontal_flip = True, \n",
    "                            width_shift_range=0.2, fill_mode = 'nearest' )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flow from directory\n",
    "train_dataset = train_dataset.flow_from_directory(train_path, target_size=(224, 224), batch_size=16, class_mode='sparse')\n",
    "\n",
    "val_dataset = val_datagen.flow_from_directory(val_path, target_size=(224, 224), batch_size=8, class_mode= 'sparse')\n",
    "\n",
    "test_dataset = val_datagen.flow_from_directory(test_path,target_size=(224, 224),batch_size = 32, class_mode= 'sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 model training with frozen layers\n",
    "freeze_model = model16.fit(train_dataset,steps_per_epoch=100,epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the accuracy of the model\n",
    "freeze_accuracy=model16.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unfreezing the layers\n",
    "for layer in model16.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning the model\n",
    "lr = 1e-5 #Learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "#Implement early stopping \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "#Compile the model \n",
    "model16.compile(optimizer= tf.keras.optimizers.RMSprop(lr_schedule),loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 with unfrozen layers\n",
    "unfrozen_model = model16.fit(train_dataset, steps_per_epoch=100,epochs=50, validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save accuracy scores in an array \n",
    "accuracy_Scores = list(unfrozen_model.unfrozen_model['accuracy'])\n",
    "accuracy_Scores.sort(reverse=True)#Sort the array in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the accuracy scores of each layer\n",
    "accuracy_Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation \n",
    "final_Accuracy = model16.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the final accuracy score\n",
    "final_Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A graph to show the training and validation accuracy graph\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(unfrozen_model.history['accuracy'],label = 'Training Accuracy ')\n",
    "plt.plot(unfrozen_model.history['val_accuracy'],label = 'Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training V Validation Accuracy')\n",
    "\n",
    "#Training and Validation Loss\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(unfrozen_model.history['accuracy'],label= 'Training Loss')\n",
    "plt.plot(unfrozen_model.history['val_accuracy'],label= 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training V Validation Loss\")\n",
    "#Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics#\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Performance Summary of Convolutional Neural Network on test data\")\n",
    "\n",
    "#Show classification report \n",
    "print(classification_report(test_dataset.classes, model16.predict(test_dataset).argmax(axis=1)))\n",
    "\n",
    "#Show confusion matrix\n",
    "sns.heatmap(confusion_matrix(test_dataset.classes, model16.predict(test_dataset).argmax(axis=1)))\n",
    "#Change to a sns heatmap\n",
    "sns.heatmap(classification_report(test_dataset.classes, model16.predict(test_dataset).argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model16 = keras.models.load_model(\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_VGG16_sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr #Gradio to show the model working\n",
    "def c_n_p(img):#Function which will take in an image\n",
    "    img = img.reshape((1,64,64,3,1))#Reshape the image to the required shape\n",
    "    pred = model16.predict(img).tolist()[0]#Receive a model and predict it\n",
    "    class_names = ['COVID-19','Normal','Pneumonia']#Introduce the three classes used in the training model\n",
    "    return{class_names[i]:pred[i] for i in range(len(class_names))}#Check the class name and compare it to the prediction\n",
    "\n",
    "im = gr.inputs.Image(shape=(6144,2),image_mode='L',invert_colors=False,source=\"upload\")#Input image\n",
    "\n",
    "ui = gr.Interface(fn=c_n_p,inputs=im,outputs=gr.outputs.Label(),title=\"XRay Classifier\",\n",
    "                article=\"This is a demo to show the classification of images between three classes: COVID, Pneumonia and Healthy XRay.\")#UserInterface\n",
    "\n",
    "ui.launch(share=True)#Launch the user interface with share, creating a shareable link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.layers import Add, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#Input\n",
    "model50 = resnet50.ResNet50(weights='imagenet',include_top=False,input_shape=(64,64,3))#Load the pretrained model\n",
    "\n",
    "for layer in model50.layers:\n",
    "    layer.trainable = False #Freeze the layers\n",
    "#Output \n",
    "output = model50.output\n",
    "#Pooling layer\n",
    "output = keras.layers.GlobalAveragePooling2D()(output)#Global average pooling\n",
    "output = keras.layers.Dense(128,activation='relu')(output)#Dense Layer\n",
    "predictions = keras.layers.Dense(12,activation='sigmoid')(output)#Dense Layer\n",
    "\n",
    "model50 = keras.models.Model(inputs=model50.input,outputs=predictions)#Grouping the layers\n",
    "\n",
    "lr = 0.1#Learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "\n",
    "model50.compile(loss= 'sparse_categorical_crossentropy',optimizer= tf.keras.optimizers.Adam(lr_schedule),metrics=['accuracy'])#Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 model training with frozen layers\n",
    "freeze_model50 = model50.fit(train_dataset,steps_per_epoch=100,epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_accuracy50 = model50.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in model50.layers:\n",
    "    layers.trainable = True#Unfreezing the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5 #New Learning rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)#Implement early stopping, where after 5 epochs the model will stop training if there is no improvement\n",
    "model50.compile(optimizer=tf.keras.optimizers.RMSprop(lr_schedule),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=[keras.metrics.SparseCategoricalAccuracy()])#Compile the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50 model training with frozen layers\n",
    "unfreeze_model50 = model50.fit(train_dataset,steps_per_epoch=100,epochs=50,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_accuracy50 = model50.evaluate(test_dataset)#Accuracy of the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model50 = tf.keras.models.save_model(model50,\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_ResNet_50_sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EfficientNetB3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import efficientnet\n",
    "modelb3 = efficientnet.EfficientNetB3(weights='imagenet',include_top=False,input_shape=(64,64,3))\n",
    "\n",
    "for i in modelb3.layers:\n",
    "    i.trainable = False\n",
    "\n",
    "output = modelb3.output\n",
    "#The Average Pooling Layer\n",
    "output = keras.layers.GlobalAveragePooling2D()(output)#Pooling operation for spatial data(Data that directly or indirectly references spatial information)\n",
    "output = keras.layers.Dense(128, activation='relu')(output)#Dense indicates the number of neurons in the layer, 128 Neurons \n",
    "#The classification Layer\n",
    "predictions = keras.layers.Dense(12, activation='sigmoid')(output)#12 Neurons \n",
    "#The final Model\n",
    "modelb3 = keras.models.Model(inputs=modelb3.input, outputs=predictions)#Group the layers into an object with training and interface features\n",
    "#Learning rate\n",
    "lr = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr, decay_steps=10000, decay_rate=0.96, staircase=True)#Learning Rate schedule that uses exponential decay schedule\n",
    "#Model Compilation\n",
    "modelb3.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_accuracyv3 = modelb3.fit(train_dataset,steps_per_epoch=100,epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in modelb3.layers:\n",
    "    layers.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)#Implement early stopping, where after 5 epochs the model will stop training if there is no improvement\n",
    "modelb3.compile(optimizer=tf.keras.optimizers.RMSprop(lr_schedule),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=[keras.metrics.SparseCategoricalAccuracy()])#Compile the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_modelb3 = modelb3.fit(train_dataset,steps_per_epoch=100,epochs=50,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb3_accuracy = modelb3.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb3 = tf.keras.models.save_model(modelb3,\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_EfficientNet_B3_sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**InceptionV3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "modelv3 = inception_v3.InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "\n",
    "for i in modelv3.layers:\n",
    "    i.trainable = False\n",
    "\n",
    "output = modelv3.output\n",
    "\n",
    "output = keras.layers.GlobalAveragePooling2D()(output)\n",
    "output = keras.layers.Dense(128,activation='relu')(output)\n",
    "predictions = keras.layers.Dense(12,activation='sigmoid')(output)\n",
    "\n",
    "modelv3 = keras.models.Model(inputs=modelv3.input,outputs=predictions)\n",
    "\n",
    "lr = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "\n",
    "modelv3.compile(loss= 'sparse_categorical_crossentropy',optimizer= tf.keras.optimizers.Adam(lr_schedule),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_modelv3 = modelv3.fit(train_dataset,steps_per_epoch=100,epochs=20,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in modelv3.layers:\n",
    "    layers.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(lr,decay_steps =100000,decay_rate = 0.96, staircase = True)\n",
    "modelv3.compile(optimizer=tf.keras.optimizers.RMSprop(lr_schedule),loss=keras.losses.SparseCategoricalCrossentropy(),metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_accuracyv3 = modelv3.fit(train_dataset,steps_per_epoch=100,epochs=50,validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv3_accuracy = modelv3.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv3 = tf.keras.models.load_model(\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_Inception_V3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelb3 = tf.keras.models.load_model(\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_EfficientNet_B3_sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model50 = tf.keras.models.load_model(\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_ResNet_50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv3 = tf.keras.models.load_model(\"C:/Users/tedjo/Downloads/XRAY/COVID_Pneumonia_Normal_Inception_V3_sigmoid.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics#\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Performance Summary of VGG16 Network on test data\")\n",
    "\n",
    "#Show classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_dataset.classes, model16.predict(test_dataset).argmax(axis=1)))\n",
    "print('\\n')\n",
    "#Show confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_dataset.classes, model16.predict(test_dataset).argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics#\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Performance Summary of EfficientNetB3 Network on test data\")\n",
    "\n",
    "#Show classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_dataset.classes, modelb3.predict(test_dataset).argmax(axis=1)))\n",
    "print('\\n')\n",
    "#Show confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_dataset.classes, modelb3.predict(test_dataset).argmax(axis=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics#\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Performance Summary of ResNet50 Network on test data\")\n",
    "\n",
    "#Show classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_dataset.classes, model50.predict(test_dataset).argmax(axis=1)))\n",
    "print('\\n')\n",
    "#Show confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_dataset.classes, model50.predict(test_dataset).argmax(axis=1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import metrics#\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(\"Performance Summary of InceptionV3 Network on test data\")\n",
    "\n",
    "#Show classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_dataset.classes, modelv3.predict(test_dataset).argmax(axis=1)))\n",
    "\n",
    "print('\\n')\n",
    "#Show confusion matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(test_dataset.classes, modelv3.predict(test_dataset).argmax(axis=1)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96b2eb5dca19ff3a7265c3bde99fee8ef2b3e674dd68fdad94fb80965a0d3477"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensor_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
